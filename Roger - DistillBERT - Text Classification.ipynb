{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install -q transformers\n",
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-06-04T21:47:09.871732Z",
     "iopub.execute_input": "2023-06-04T21:47:09.872080Z",
     "iopub.status.idle": "2023-06-04T21:47:09.877262Z",
     "shell.execute_reply.started": "2023-06-04T21:47:09.872052Z",
     "shell.execute_reply": "2023-06-04T21:47:09.876180Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T21:47:09.882649Z",
     "iopub.execute_input": "2023-06-04T21:47:09.882912Z",
     "iopub.status.idle": "2023-06-04T21:47:09.889275Z",
     "shell.execute_reply.started": "2023-06-04T21:47:09.882890Z",
     "shell.execute_reply": "2023-06-04T21:47:09.888186Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/kaggle/input/jigsaw/train.csv\")\n",
    "df['list'] = df[df.columns[2:]].values.tolist()\n",
    "new_df = df[['comment_text', 'list']].copy()\n",
    "new_df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T21:47:09.891511Z",
     "iopub.execute_input": "2023-06-04T21:47:09.891826Z",
     "iopub.status.idle": "2023-06-04T21:47:11.167600Z",
     "shell.execute_reply.started": "2023-06-04T21:47:09.891796Z",
     "shell.execute_reply": "2023-06-04T21:47:11.166389Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "execution_count": 31,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                        comment_text                list\n0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:06:19.209390Z",
     "iopub.execute_input": "2023-06-04T22:06:19.210073Z",
     "iopub.status.idle": "2023-06-04T22:06:19.285838Z",
     "shell.execute_reply.started": "2023-06-04T22:06:19.210041Z",
     "shell.execute_reply": "2023-06-04T22:06:19.284913Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.comment_text\n",
    "        self.targets = self.data.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "            }"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:06:21.583013Z",
     "iopub.execute_input": "2023-06-04T22:06:21.583357Z",
     "iopub.status.idle": "2023-06-04T22:06:21.592829Z",
     "shell.execute_reply.started": "2023-06-04T22:06:21.583329Z",
     "shell.execute_reply": "2023-06-04T22:06:21.591874Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:06:38.051680Z",
     "iopub.execute_input": "2023-06-04T22:06:38.052026Z",
     "iopub.status.idle": "2023-06-04T22:06:38.097295Z",
     "shell.execute_reply.started": "2023-06-04T22:06:38.051997Z",
     "shell.execute_reply": "2023-06-04T22:06:38.096272Z"
    },
    "trusted": true
   },
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": "FULL Dataset: (159571, 2)\nTRAIN Dataset: (127657, 2)\nTEST Dataset: (31914, 2)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:06:40.165778Z",
     "iopub.execute_input": "2023-06-04T22:06:40.166149Z",
     "iopub.status.idle": "2023-06-04T22:06:40.178316Z",
     "shell.execute_reply.started": "2023-06-04T22:06:40.166112Z",
     "shell.execute_reply": "2023-06-04T22:06:40.177198Z"
    },
    "trusted": true
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = torch.nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, return_dict = False)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:08:01.599638Z",
     "iopub.execute_input": "2023-06-04T22:08:01.599984Z",
     "iopub.status.idle": "2023-06-04T22:08:01.607024Z",
     "shell.execute_reply.started": "2023-06-04T22:08:01.599956Z",
     "shell.execute_reply": "2023-06-04T22:08:01.605868Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:08:04.457857Z",
     "iopub.execute_input": "2023-06-04T22:08:04.458206Z",
     "iopub.status.idle": "2023-06-04T22:08:05.103075Z",
     "shell.execute_reply.started": "2023-06-04T22:08:04.458179Z",
     "shell.execute_reply": "2023-06-04T22:08:05.102116Z"
    },
    "trusted": true
   },
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "text": "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
     "output_type": "stream"
    },
    {
     "execution_count": 60,
     "output_type": "execute_result",
     "data": {
      "text/plain": "DistillBERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating the loss function and optimizer\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:08:06.839894Z",
     "iopub.execute_input": "2023-06-04T22:08:06.840253Z",
     "iopub.status.idle": "2023-06-04T22:08:06.845880Z",
     "shell.execute_reply.started": "2023-06-04T22:08:06.840222Z",
     "shell.execute_reply": "2023-06-04T22:08:06.844927Z"
    },
    "trusted": true
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:08:08.090087Z",
     "iopub.execute_input": "2023-06-04T22:08:08.090468Z",
     "iopub.status.idle": "2023-06-04T22:08:08.098662Z",
     "shell.execute_reply.started": "2023-06-04T22:08:08.090410Z",
     "shell.execute_reply": "2023-06-04T22:08:08.097681Z"
    },
    "trusted": true
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:08:09.822019Z",
     "iopub.execute_input": "2023-06-04T22:08:09.822420Z",
     "iopub.status.idle": "2023-06-04T22:46:51.645401Z",
     "shell.execute_reply.started": "2023-06-04T22:08:09.822390Z",
     "shell.execute_reply": "2023-06-04T22:46:51.644475Z"
    },
    "trusted": true
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "text": "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch: 0, Loss:  0.7302364706993103\nEpoch: 0, Loss:  0.024416273459792137\nEpoch: 0, Loss:  0.21426531672477722\nEpoch: 0, Loss:  0.0010854839347302914\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:46:51.647636Z",
     "iopub.execute_input": "2023-06-04T22:46:51.647986Z",
     "iopub.status.idle": "2023-06-04T22:46:51.655473Z",
     "shell.execute_reply.started": "2023-06-04T22:46:51.647954Z",
     "shell.execute_reply": "2023-06-04T22:46:51.654552Z"
    },
    "trusted": true
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-04T22:46:51.656830Z",
     "iopub.execute_input": "2023-06-04T22:46:51.657455Z",
     "iopub.status.idle": "2023-06-04T22:51:14.527329Z",
     "shell.execute_reply.started": "2023-06-04T22:46:51.657409Z",
     "shell.execute_reply": "2023-06-04T22:51:14.526291Z"
    },
    "trusted": true
   },
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy Score = 0.926333270664912\nF1 Score (Micro) = 0.7877968994453135\nF1 Score (Macro) = 0.6431468740536789\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
