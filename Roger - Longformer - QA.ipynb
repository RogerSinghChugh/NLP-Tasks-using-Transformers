{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q datasets transformers \n",
        "# !pip install --upgrade accelerate\n",
        "import transformers\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoTokenizer, default_data_collator"
      ],
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:50.843514Z",
          "iopub.execute_input": "2023-06-05T21:12:50.844091Z",
          "iopub.status.idle": "2023-06-05T21:12:50.849209Z",
          "shell.execute_reply.started": "2023-06-05T21:12:50.844051Z",
          "shell.execute_reply": "2023-06-05T21:12:50.848187Z"
        },
        "trusted": true
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n",
        "# answers are allowed or not).\n",
        "squad_v2 = False\n",
        "model_checkpoint = \"allenai/longformer-base-4096\"\n",
        "batch_size = 2"
      ],
      "metadata": {
        "id": "zVvslsfMIrIh",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:50.851330Z",
          "iopub.execute_input": "2023-06-05T21:12:50.851740Z",
          "iopub.status.idle": "2023-06-05T21:12:50.863787Z",
          "shell.execute_reply.started": "2023-06-05T21:12:50.851708Z",
          "shell.execute_reply": "2023-06-05T21:12:50.862638Z"
        },
        "trusted": true
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "metadata": {
        "id": "IreSlFmlIrIm",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:50.868247Z",
          "iopub.execute_input": "2023-06-05T21:12:50.868958Z",
          "iopub.status.idle": "2023-06-05T21:12:50.878457Z",
          "shell.execute_reply.started": "2023-06-05T21:12:50.868925Z",
          "shell.execute_reply": "2023-06-05T21:12:50.877508Z"
        },
        "trusted": true
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = load_dataset(\"squad_adversarial\", \"AddSent\", split=  \"validation[:80%]\")\n",
        "vaild_data = load_dataset(\"squad_adversarial\", \"AddSent\", split = \"validation[80%:100%]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_AY1ATSIrIq",
        "outputId": "beefc3f6-e15e-46ec-821a-2b3633a12548",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:50.885658Z",
          "iopub.execute_input": "2023-06-05T21:12:50.886458Z",
          "iopub.status.idle": "2023-06-05T21:12:51.410610Z",
          "shell.execute_reply.started": "2023-06-05T21:12:50.886420Z",
          "shell.execute_reply": "2023-06-05T21:12:51.409726Z"
        },
        "trusted": true
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset squad_adversarial (/root/.cache/huggingface/datasets/squad_adversarial/AddSent/1.1.0/e9df92c060f50eb529284b303c504bf4359ba37944faebe7a16a91b7d534e946)\n",
            "WARNING:datasets.builder:Found cached dataset squad_adversarial (/root/.cache/huggingface/datasets/squad_adversarial/AddSent/1.1.0/e9df92c060f50eb529284b303c504bf4359ba37944faebe7a16a91b7d534e946)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:51.412092Z",
          "iopub.execute_input": "2023-06-05T21:12:51.412719Z",
          "iopub.status.idle": "2023-06-05T21:12:51.917370Z",
          "shell.execute_reply.started": "2023-06-05T21:12:51.412685Z",
          "shell.execute_reply": "2023-06-05T21:12:51.916284Z"
        },
        "trusted": true
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "metadata": {
        "id": "pgCBz72W4bSK",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:51.919039Z",
          "iopub.execute_input": "2023-06-05T21:12:51.919707Z",
          "iopub.status.idle": "2023-06-05T21:12:51.924630Z",
          "shell.execute_reply.started": "2023-06-05T21:12:51.919673Z",
          "shell.execute_reply": "2023-06-05T21:12:51.923477Z"
        },
        "trusted": true
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\""
      ],
      "metadata": {
        "id": "U46ITcqS4bSP",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:51.930170Z",
          "iopub.execute_input": "2023-06-05T21:12:51.931018Z",
          "iopub.status.idle": "2023-06-05T21:12:51.939504Z",
          "shell.execute_reply.started": "2023-06-05T21:12:51.930980Z",
          "shell.execute_reply": "2023-06-05T21:12:51.938488Z"
        },
        "trusted": true
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "sajq0L524bSP",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:51.943784Z",
          "iopub.execute_input": "2023-06-05T21:12:51.944454Z",
          "iopub.status.idle": "2023-06-05T21:12:51.962295Z",
          "shell.execute_reply.started": "2023-06-05T21:12:51.944418Z",
          "shell.execute_reply": "2023-06-05T21:12:51.961216Z"
        },
        "trusted": true
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_data.map(preprocess_function, batched=True)\n",
        "valid_dataset = vaild_data.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2d96e7-9b99-4e0c-dcee-d55c404cbf36",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:51.963970Z",
          "iopub.execute_input": "2023-06-05T21:12:51.964583Z",
          "iopub.status.idle": "2023-06-05T21:12:55.348226Z",
          "shell.execute_reply.started": "2023-06-05T21:12:51.964550Z",
          "shell.execute_reply": "2023-06-05T21:12:55.345424Z"
        },
        "trusted": true
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_adversarial/AddSent/1.1.0/e9df92c060f50eb529284b303c504bf4359ba37944faebe7a16a91b7d534e946/cache-89bfd526f25049af.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_adversarial/AddSent/1.1.0/e9df92c060f50eb529284b303c504bf4359ba37944faebe7a16a91b7d534e946/cache-c5d63dfbee7ed0bb.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c18d797-f03a-4a12-cac0-aae0a6202c05",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:55.349425Z",
          "iopub.status.idle": "2023-06-05T21:12:55.349969Z",
          "shell.execute_reply.started": "2023-06-05T21:12:55.349711Z",
          "shell.execute_reply": "2023-06-05T21:12:55.349733Z"
        },
        "trusted": true
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForQuestionAnswering: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerForQuestionAnswering were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"test-squad\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "Bliy8zgjIrJY",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:55.352126Z",
          "iopub.status.idle": "2023-06-05T21:12:55.352570Z",
          "shell.execute_reply.started": "2023-06-05T21:12:55.352344Z",
          "shell.execute_reply": "2023-06-05T21:12:55.352365Z"
        },
        "trusted": true
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = default_data_collator"
      ],
      "metadata": {
        "id": "ovY-yit14bSS",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:55.356473Z",
          "iopub.status.idle": "2023-06-05T21:12:55.356929Z",
          "shell.execute_reply.started": "2023-06-05T21:12:55.356687Z",
          "shell.execute_reply": "2023-06-05T21:12:55.356708Z"
        },
        "trusted": true
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"qa_roBERTa\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "imY1oC3SIrJf",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:55.358745Z",
          "iopub.status.idle": "2023-06-05T21:12:55.359211Z",
          "shell.execute_reply.started": "2023-06-05T21:12:55.358987Z",
          "shell.execute_reply": "2023-06-05T21:12:55.359008Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "cdcd62a1-3d8e-4f84-efc2-fbeacc3bdf9d"
      },
      "execution_count": 126,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6977' max='8544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6977/8544 41:59 < 09:26, 2.77 it/s, Epoch 2.45/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.769700</td>\n",
              "      <td>3.466273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166700</td>\n",
              "      <td>4.220368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8544' max='8544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8544/8544 52:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.769700</td>\n",
              "      <td>3.466273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166700</td>\n",
              "      <td>4.220368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.067300</td>\n",
              "      <td>4.750650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8544, training_loss=0.5953808149378677, metrics={'train_runtime': 3147.1509, 'train_samples_per_second': 2.715, 'train_steps_per_second': 2.715, 'total_flos': 2092926538137600.0, 'train_loss': 0.5953808149378677, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "execution": {
          "iopub.status.busy": "2023-06-05T21:12:55.361021Z",
          "iopub.status.idle": "2023-06-05T21:12:55.361463Z",
          "shell.execute_reply.started": "2023-06-05T21:12:55.361239Z",
          "shell.execute_reply": "2023-06-05T21:12:55.361260Z"
        },
        "trusted": true
      },
      "execution_count": 126,
      "outputs": []
    }
  ]
}